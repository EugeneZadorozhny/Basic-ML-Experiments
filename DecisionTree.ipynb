{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import graphviz\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Abalone\n",
    "`load_abalone` loads the csv file from the provided path and sets the column names. Also deletes unwanted features from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abalone(path):\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df.set_axis([\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \"shucked weight\",\n",
    "                 \"viscera weight\", \"shell weight\", \"rings\"], axis=1, inplace=True)\n",
    "    df = df.drop(columns = ['sex'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Breast Cancer\n",
    "`load_breast_cancer` loads the csv file from the provided path and sets the column names. Also deletes unwanted features from the dataset and imputes missing values with the mean of the column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_breast_cancer(path):\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df.set_axis([\"sample code number\", \"clump thickness\", \"uniformity of cell size\", \"uniformity of cell shape\",\n",
    "                 \"marginal adhesion\", \"single epithelial cell size\",\n",
    "                 \"bare nuclei\", \"bland chromatin\", \"normal nucleoli\", \"mitoses\", \"class\"], axis=1, inplace=True)\n",
    "    df = df.drop(columns = [\"sample code number\"])\n",
    "    df = df.replace('?', np.nan)\n",
    "    df['bare nuclei'] = df['bare nuclei'].astype(float)\n",
    "    df = impute_mean(df, 'bare nuclei', int)\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Car\n",
    "`load_car` loads the csv file from the provided path and sets the column names."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_car(path):\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df.set_axis([\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Forest Fires\n",
    "`load_forest_fires` loads the csv file from the provided path and sets the column names. Also deletes unwanted features from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_forest_fires(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop(columns=['X', 'Y', 'month', 'day'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load House Votes\n",
    "`load_house_votes` loads the csv file from the provided path and sets the column names."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_house_votes(path):\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df.set_axis([\"class\", \"handicapped infants\", \"water project cost sharing\", \"adoption of the budget resolution\",\n",
    "                 \"physician fee freeze\", \"el salvador aid\", \"religious groups in schools\", \"anti satellite test ban\",\n",
    "                 \"aid to nicaraguan contras\", \"mx missile\", \"immigration\", \"synfuels corporation cutback\",\n",
    "                 \"education spending\", \"superfund right to sue\", \"crime\", \"duty free exports\",\n",
    "                 \"export administration act south africa\"], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Machine\n",
    "`load_machine` loads the csv file from the provided path and sets the column names. Also deletes unwanted features from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_machine(path):\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    df.set_axis([\"vendor\", \"model\", \"MYCT\", \"MMIN\", \"MMAX\", \"CACH\", \"CHMIN\", \"CHMAX\", \"PRP\", \"ERP\"], axis=1, inplace=True)\n",
    "    df = df.drop([\"vendor\",\"model\", \"ERP\"], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Impute Mean\n",
    "`impute_mean` updates the missing values in a column of the dataset with the mean of the specified column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mean(data, column, data_type):\n",
    "    _data = deepcopy(data)\n",
    "    mean = _data[column].mean()\n",
    "    _data[column] = _data[column].fillna(mean)\n",
    "    if data_type == int:\n",
    "        _data[column] = _data[column].astype(np.int64)\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode Ordinal\n",
    "`encode_ordinal` encodes ordinal values of a feature based on the relationship list provided."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ordinal(data, column, relationship):\n",
    "    _data = deepcopy(data)\n",
    "    for index, r in enumerate(relationship):\n",
    "        _data[column] = _data[column].replace(r, index)\n",
    "        print(f\"encoding column: {column} - value: {r} as: {index}\")\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One Hot Encode\n",
    "`one_hot_encode` encodes features of the desired columns with one hot values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data, columns):\n",
    "    _data = deepcopy(data)\n",
    "    for _column in columns:\n",
    "        _data2 = pd.get_dummies(_data[_column]).groupby(level=0,axis=1).max().add_prefix(_column + ' - ')\n",
    "        _data = pd.concat([_data, _data2], axis=1)\n",
    "        _data = _data.drop([_column], axis=1)\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discretize Feature\n",
    "`discretize_feature` bins feature values based on the desired bin type. Frequency type tries to ensure the same number of data points are in each bin and bins can vary in width. Width type specifies the bin width so the number on points in each bin can vary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_feature(data, columns, number_bins, type_bins):\n",
    "    _data = deepcopy(data)\n",
    "    for _column in columns:\n",
    "        if type_bins == \"frequency\":\n",
    "            _data2 = pd.qcut(_data[_column], q = number_bins, precision=0, duplicates='drop')\n",
    "            _data[_column] = _data2\n",
    "\n",
    "        if type_bins == \"width\":\n",
    "            _data2 = pd.cut(_data[_column], number_bins)\n",
    "            _data[_column] = _data2\n",
    "\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardize\n",
    "`standardize` updates values in training data and test data to the z standard using the mean and standard deviation from the training set for both calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(training_data, test_data, columns):\n",
    "    _data_train = deepcopy(training_data)\n",
    "    _data_test = deepcopy(test_data)\n",
    "    for _column in columns:\n",
    "        mean = _data_train[_column].mean()\n",
    "        std = _data_train[_column].std()\n",
    "        z_train = (_data_train[_column] - mean)/std\n",
    "        z_test = (_data_test[_column] - mean)/std\n",
    "\n",
    "        _data_train[_column] = z_train\n",
    "        _data_test[_column] = z_test\n",
    "    return _data_train, _data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract Validation Set\n",
    "`extract_validation_set` extracts a random 20% sample for the validation set. Evenly samples the groupings of the output. Randomly shuffles the remaining 80%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_validation_set(data, class_column):\n",
    "    _data = deepcopy(data)\n",
    "    y = class_column\n",
    "\n",
    "    stratify_20 = _data.groupby(y, group_keys=False).sample(frac=0.20)\n",
    "    stratify_80 = _data.drop(stratify_20.index).sample(frac=1)\n",
    "\n",
    "    return stratify_80, stratify_20"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Train Test\n",
    "`create_train_test` takes in the folds of a k-fold to create a test set from 1 fold and a training set from the remaing 4 folds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(folds, index):\n",
    "    training = pd.DataFrame()\n",
    "    test = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        if i == index:\n",
    "            test = fold\n",
    "        else:\n",
    "            training = pd.concat([training, fold])\n",
    "    return training, test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stratified K Fold\n",
    "`stratified_k_fold` takes the provided dataset and creates a specified number of evenly distributed folds of that data while maintaining output grouping distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold(data, k, class_column):\n",
    "    y = class_column\n",
    "    split = []\n",
    "    unique_keys = data.value_counts(subset=y, normalize=True).keys()\n",
    "    split_class = [data.loc[data[y] == keys] for keys in unique_keys]\n",
    "\n",
    "    for class_value in split_class:\n",
    "        d, m = divmod(len(class_value), k)\n",
    "        split.append(list(class_value[i * d + min(i, m):(i + 1) * d + min(i + 1, m)] for i in range(k)))\n",
    "\n",
    "    folds = [pd.concat([split[i][c] for i in range(len(unique_keys))]) for c in range(k)]\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K Fold\n",
    "`k_fold` takes the provided dataset and creates a specified number of evenly distributed folds of that data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(data, k):\n",
    "\n",
    "    d, m = divmod(len(data), k)\n",
    "    folds = list(data[i * d + min(i, m):(i + 1) * d + min(i + 1, m)] for i in range(k))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K Fold Cross Validation Sets\n",
    "`k_fold_cross_validation_sets` splits the data into validation and train/test sets. Folds the sets k times. Can fold with stratification or without stratification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation_sets(data, k, class_column, stratified=True, validation=True):\n",
    "    if validation:\n",
    "        train, validation = extract_validation_set(data, class_column)\n",
    "        if stratified:\n",
    "            train = stratified_k_fold(train, k, class_column)\n",
    "            #validation = stratified_k_fold(validation, k, class_column)\n",
    "        else:\n",
    "            train = k_fold(train, k)\n",
    "            #validation = k_fold(validation, k)\n",
    "        return train, validation\n",
    "    else:\n",
    "        if stratified:\n",
    "            train = stratified_k_fold(data, k, class_column)\n",
    "        else:\n",
    "            train = k_fold(data, k)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "`evaluation` applies an evaluation metric on the predicted values. Able to use a classification score by comparing ground truth to the predicted values to determine how many are correct. Able to use Mean Square Error to determine the distance between the ground truth and the predicted values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(ground_truth, predicted_values, metric):\n",
    "    if metric == 'classification_score':\n",
    "        count = 0\n",
    "        for index, value in enumerate(ground_truth):\n",
    "            if predicted_values[index] == value:\n",
    "                count += 1\n",
    "        count = count/len(ground_truth)\n",
    "        return count\n",
    "    if metric == 'mse':\n",
    "        error = sum((np.array(ground_truth) - np.array(predicted_values))**2)/len(ground_truth)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prior Entropy\n",
    "`prior_entropy` performs the entropy calculation of a dataset for each class in the dataset. Used for data in the form of a dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_entropy(data):\n",
    "    #determines the number of each class in the dataset\n",
    "    class_counts = data.value_counts()\n",
    "    #calculate the entropy for the dataset\n",
    "    entropy = -1 * sum((class_counts/len(data))*np.log2(class_counts/len(data)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prior Entropy Numeric\n",
    "`prior_entropy_numeric` performs the entropy calculation of a dataset for each class in the dataset. Used for data in the form of a numpy array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_entropy_numeric(class_column):\n",
    "    entropy = []\n",
    "    #get the unique values of a class and the counts associated with each unique value\n",
    "    unique, counts = np.unique(class_column, return_counts=True)\n",
    "    data_length = len(class_column)\n",
    "    #calculate the entropy for the dataset\n",
    "    for value in counts:\n",
    "        entropy.append(value/data_length * np.log2(value/data_length))\n",
    "    entropy = -1 * sum(entropy)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Expected Entropy Discrete\n",
    "`expected_entropy_discrete` calculates the expected entropy after a split. The data is split by the feature value for the entropy calculation. Used for features with discrete values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_entropy_discrete(data, feature, class_column):\n",
    "    entropy = []\n",
    "    intrinsic_value = []\n",
    "    #calculate the unique feature values and their counts\n",
    "    feature_value_counts = data[feature].value_counts()\n",
    "    for key, value in feature_value_counts.items():\n",
    "        #get a subset of the data by feature value\n",
    "        subset = data[data[feature] == key]\n",
    "        #calculate intrinsic value of the subset\n",
    "        intrinsic_value.append((value/len(data)) * np.log2(value/len(data)))\n",
    "        #calculate the entropy of the subset\n",
    "        h = prior_entropy(subset[class_column])\n",
    "        entropy.append(value/len(data) * h)\n",
    "    intrinsic_value = -1 * sum(intrinsic_value)\n",
    "    #total expected entropy for the feature\n",
    "    entropy = sum(entropy)\n",
    "    return entropy, intrinsic_value"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Expected Entropy Numeric\n",
    "`expected_entropy_numeric` calculates the expected entropy after a split. Each sample were the value of a feature changes is considered for the split. The split value with the lowest entropy is selected as the split location for that feautre. Used for features with continuous numeric values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_entropy_numeric(data, feature_np, class_column):\n",
    "    entropy, intrinsic_value, split_value = ([] for i in range(3))\n",
    "    for index in range(len(data)-1):\n",
    "        #split the data at the next sample\n",
    "        split = (data[index][feature_np] + data[index+1][feature_np]) / 2\n",
    "        subset1, subset2 = data[:index+1], data[index+1:]\n",
    "        #if the two adjacent samples have the same value go to use the next sample as the split\n",
    "        if data[index][feature_np] == data[index+1][feature_np]:\n",
    "            continue\n",
    "        #calculate intrinsic value of the split\n",
    "        intrinsic_value.append(((len(subset1)/len(data)) * np.log2(len(subset1)/len(data))) + ((len(subset2)/len(data)) * np.log2(len(subset2)/len(data))))\n",
    "        #calculate the entropy of the split\n",
    "        h1, h2 = prior_entropy_numeric(np.transpose(subset1)[class_column]), prior_entropy_numeric(np.transpose(subset2)[class_column])\n",
    "        entropy.append((len(subset1)/len(data) * h1) + (len(subset2)/len(data) * h2))\n",
    "        split_value.append(split)\n",
    "    if len(intrinsic_value) == 0:\n",
    "        intrinsic_value.append(0)\n",
    "        entropy.append(prior_entropy_numeric(np.transpose(data)[class_column]))\n",
    "        split_value.append(np.inf)\n",
    "    # find the split with the minimum entropy to use as the split value\n",
    "    intrinsic_value = -1 * intrinsic_value[np.argmin(entropy)]\n",
    "    split_value = split_value[np.argmin(entropy)]\n",
    "    entropy = min(entropy)\n",
    "    return entropy, intrinsic_value, split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gain Ratio\n",
    "`gain_ratio` calculate the gain ratio for a feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(data, feature, class_column):\n",
    "    prior = prior_entropy(data[class_column])\n",
    "    #use numeric entropy calculation if feature values are type float\n",
    "    if data[feature].dtypes == np.float64:\n",
    "        class_column = data.columns.get_loc(class_column)\n",
    "        feature_np = data.columns.get_loc(feature)\n",
    "        data = data.sort_values([feature]).to_numpy()\n",
    "        expected, intrinsic_value, split_value = expected_entropy_numeric(data, feature_np, class_column)\n",
    "    #use discrete entropy calculation if features are not type float\n",
    "    else:\n",
    "        expected, intrinsic_value = expected_entropy_discrete(data, feature, class_column)\n",
    "        split_value = None\n",
    "    #calcualte the gain\n",
    "    gain = round(prior, 5) - round(expected, 5)\n",
    "    #calculate the gain ratio if a gain value is returned. Else return 0 gain ratio\n",
    "    if gain != 0:\n",
    "        gain_r = round(gain/intrinsic_value, 5)\n",
    "    else:\n",
    "        gain_r = 0\n",
    "    return gain_r, split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Feature Classification\n",
    "`best_feature_classification` determines the best feature to split on by looking at the gain ratios produced by each feature. Used for classification decision tree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_classification(data, class_column):\n",
    "    gains = {}\n",
    "    best = [-1, -1]\n",
    "    for key in data:\n",
    "        #calculate a gain ratio if column is not the class\n",
    "        if key != class_column:\n",
    "            gains[key] = gain_ratio(data, key, class_column)\n",
    "    #find the feature with the highest gain ratio\n",
    "    for key, value in gains.items():\n",
    "        if value[0] > best[1]:\n",
    "            best[1] = value[0]\n",
    "            best[0] = key\n",
    "    return {best[0]: gains[best[0]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Classification\n",
    "`decision_tree_classification` creates a decision tree for classification using gain ratio as the splitting criteria"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classification(_data, class_column):\n",
    "    data = deepcopy(_data)\n",
    "    #named tuple structure to be used as label for each node\n",
    "    attr = namedtuple('attr', 'split name gain_ratio samples value value_index output')\n",
    "    #find current node entropy. If 0 or no more features to split on create a leaf node\n",
    "    prior = round(prior_entropy(data[class_column]), 5)\n",
    "    if (prior == 0) or (len(data.columns.tolist()) == 1):\n",
    "        node = {'label': attr(split = None, name = None, gain_ratio = prior, samples = len(data), value = data[class_column].value_counts().sort_index().tolist(),\n",
    "                              value_index= data[class_column].value_counts().sort_index().index.tolist(), output = data[class_column].value_counts().sort_index().idxmax())}\n",
    "        return node\n",
    "    #find best feature to split on\n",
    "    best_f = best_feature_classification(data, class_column)\n",
    "    #enter branch if feature is discrete\n",
    "    if best_f[list(best_f)[0]][1] is None:\n",
    "        #create a dictionary entry for the feature as a new node\n",
    "        node = {list(best_f)[0]: {}}\n",
    "        #create branches of the node based on best feature\n",
    "        for branch in data[list(best_f)[0]].sort_values().unique():\n",
    "            node[list(best_f)[0]][branch] = {}\n",
    "        #add label to the node to store relevant information about the node\n",
    "        node[list(best_f)[0]]['label'] = attr(split = best_f[list(best_f)[0]][1], name = str(list(best_f)[0]),\n",
    "                                              gain_ratio = best_f[list(best_f)[0]][0], samples = len(data), value = data[class_column].value_counts().sort_index().tolist(),\n",
    "                                              value_index= data[class_column].value_counts().sort_index().index.tolist(), output = data[class_column].value_counts().sort_index().idxmax())\n",
    "        #continue creating the tree by going down each branch of the new node\n",
    "        for key in node[list(best_f)[0]]:\n",
    "            if key != 'label':\n",
    "                #create subset of data that belongs to the branch\n",
    "                subset = data[data[list(best_f)[0]] == key]\n",
    "                subset = subset.drop(columns = [list(best_f)[0]])\n",
    "                #if subset is empty load the class as the subset to have the next iteration create a leaf\n",
    "                if subset.empty:\n",
    "                    subset = data[class_column].to_frame()\n",
    "                #find the next node or leaf\n",
    "                node[list(best_f)[0]][key] = decision_tree_classification(subset, class_column)\n",
    "        return node\n",
    "    #enter branch if feature is numeric\n",
    "    else:\n",
    "        #create new dictionary entry for the feature as a new node and create the branches of the node\n",
    "        node = {list(best_f)[0]: {'True': {}, 'False': {}}}\n",
    "        #add label to the node to store relevant information about the node\n",
    "        node[list(best_f)[0]]['label'] = attr(split = round(best_f[list(best_f)[0]][1], 5), name = str(list(best_f)[0]) + '<=' + str(round(best_f[list(best_f)[0]][1], 5)),\n",
    "                                              gain_ratio = best_f[list(best_f)[0]][0], samples = len(data), value = data[class_column].value_counts().sort_index().tolist(),\n",
    "                                              value_index= data[class_column].value_counts().sort_index().index.tolist(), output = data[class_column].value_counts().sort_index().idxmax())\n",
    "        #split the data based on the split value return from finding the best feature\n",
    "        subset1 = data[data[list(best_f)[0]] <= best_f[list(best_f)[0]][1]]\n",
    "        subset2 = data[data[list(best_f)[0]] > best_f[list(best_f)[0]][1]]\n",
    "        #find the next node or leaf if subset has samples\n",
    "        if len(subset1) != 0:\n",
    "            node[list(best_f)[0]]['True'] = decision_tree_classification(subset1, class_column)\n",
    "        if len(subset2) != 0:\n",
    "            node[list(best_f)[0]]['False'] = decision_tree_classification(subset2, class_column)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DT Classify\n",
    "`dt_classify` finds the output a tree predicts for the samples provided"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def dt_classify(data, tree):\n",
    "    results = []\n",
    "    for index, sample in data.iterrows():\n",
    "        results.append(traverse_tree(sample, tree))\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traverse Tree\n",
    "`traverse_tree` takes a sample and looks through the tree to find the predicted output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def traverse_tree(data, tree):\n",
    "    #look at the node and determine what feature it represents\n",
    "    feature = list(tree.keys())[0]\n",
    "    #if label then a leaf was found. Return the leaf output value\n",
    "    if feature == 'label':\n",
    "        result = tree[feature].output\n",
    "        return result\n",
    "    #find the feature value from the sample\n",
    "    value = data[feature]\n",
    "    #if feature is numeric follow the if statement\n",
    "    if list(tree[feature].keys())[0] == 'True':\n",
    "        #find the split value of the node\n",
    "        split = tree[feature]['label'].split\n",
    "        #follow the appropriate split value down the tree\n",
    "        if value <= split:\n",
    "            result = traverse_tree(data, tree[feature]['True'])\n",
    "        else:\n",
    "            result = traverse_tree(data, tree[feature]['False'])\n",
    "    #if feature is categorical follow the else statement\n",
    "    else:\n",
    "        #try to move down the tree. If feature value not in tree stop at this node to determine output value\n",
    "        try:\n",
    "            result = traverse_tree(data, tree[feature][value])\n",
    "        except KeyError:\n",
    "            result = tree[feature]['label'].output\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find Leaves\n",
    "`find_leaves` finds all the leaves of a tree and the path to the leaf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def find_leaves(tree):\n",
    "    leaf = []\n",
    "    for index, sub_tree in tree.items():\n",
    "        if type(sub_tree) is dict:\n",
    "            #if not leaf then keep going down the tree and save the path\n",
    "            if list(sub_tree.keys())[0] != 'label':\n",
    "                node = find_leaves(sub_tree)\n",
    "                for key in node:\n",
    "                    leaf.append([index, key])\n",
    "            #add leaf to the result\n",
    "            else:\n",
    "                leaf.append([index, sub_tree])\n",
    "    return leaf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Flatten\n",
    "`flatten` takes a nested list and flattens it into 1 list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def flatten(nested):\n",
    "    flat = []\n",
    "    for i in nested:\n",
    "        if isinstance(i,list):\n",
    "            flat.extend(flatten(i))\n",
    "        else:\n",
    "            flat.append(i)\n",
    "    return flat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Pruning Paths\n",
    "`create_pruning_paths` creates a list of nodes for pruning including the path to the node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def create_pruning_paths(leaves):\n",
    "    paths = []\n",
    "    unique = []\n",
    "    #take the list of leaves, flatten the lists, and delete path up to the node to be pruned\n",
    "    for i in range(len(leaves)):\n",
    "        paths.append(flatten(leaves[i]))\n",
    "        del paths[i][-3:]\n",
    "    #delete empty lists\n",
    "    paths = [x for x in paths if x != []]\n",
    "    #delete duplicate nodes\n",
    "    for x in paths:\n",
    "        if isinstance(x, list) and (x not in unique):\n",
    "            unique.append(x)\n",
    "    #sort by longest path to node\n",
    "    unique.sort(reverse=True, key=len)\n",
    "    return unique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find Pruning Nodes\n",
    "`find_pruning_nodes` finds the nodes of a tree that can be pruned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def find_pruning_nodes(tree):\n",
    "    leaves = find_leaves(tree)\n",
    "    nodes = create_pruning_paths(leaves)\n",
    "    return nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prune Nodes\n",
    "`prune_nodes` deletes a node from the tree and replaces it with a leaf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def prune_node(tree, paths):\n",
    "    if len(paths) == 0:\n",
    "        x = tree[list(tree.keys())[0]]['label']\n",
    "        tree.clear()\n",
    "        tree['label'] = x\n",
    "        return None\n",
    "    return prune_node(tree[paths[0]], paths[1:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Num Paths\n",
    "`num_paths` returns the number of paths in a tree and the length of the longest path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def num_paths(tree):\n",
    "    leaves = find_leaves(tree)\n",
    "    paths = []\n",
    "    unique = []\n",
    "    for i in range(len(leaves)):\n",
    "        paths.append(flatten(leaves[i]))\n",
    "    paths = [x for x in paths if x != []]\n",
    "    for x in paths:\n",
    "        if isinstance(x, list) and (x not in unique):\n",
    "            unique.append(x)\n",
    "    unique.sort(reverse=True, key=len)\n",
    "    return len(unique), (len(unique[0])-1)/2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation Classification\n",
    "`cross_validation_classification` K fold cross validation for a classification decision tree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def cross_validation_classification(data, class_column, post_prune = True):\n",
    "    eval_pre = []\n",
    "    eval_post = []\n",
    "    #creates the validation and test/train sets\n",
    "    folds, validation = k_fold_cross_validation_sets(data, 5, class_column)\n",
    "    #run each fold as the test set\n",
    "    for index, fold in enumerate(folds):\n",
    "        #create train test sets from folds\n",
    "        train, test = create_train_test(folds, index)\n",
    "        #create a decision tree\n",
    "        tree = decision_tree_classification(train, class_column)\n",
    "        #if pruning is selected then prune the tree\n",
    "        if post_prune:\n",
    "            #graph the un-pruned tree\n",
    "            graph_tree(data, tree, data.name + ' pre', index)\n",
    "            #determine performance of the un-pruned tree\n",
    "            result = dt_classify(test, tree)\n",
    "            eval_pre.append(evaluation(test[class_column], result, 'classification_score'))\n",
    "            #determine number of paths in the tree\n",
    "            path_count, length = num_paths(tree)\n",
    "            new_path_count = 0\n",
    "            #keep pruning until the number of paths in the tree stops changing\n",
    "            while path_count > new_path_count:\n",
    "                #find nodes to be pruned\n",
    "                nodes = find_pruning_nodes(tree)\n",
    "                #determine number of paths in the tree\n",
    "                path_count, length = num_paths(tree)\n",
    "                #test performance of pruning each node individually against the validation set\n",
    "                for n in nodes:\n",
    "                    #copy the tree\n",
    "                    prune_tree = deepcopy(tree)\n",
    "                    #determine performance of the tree\n",
    "                    result = dt_classify(validation, prune_tree)\n",
    "                    eval1 = evaluation(validation[class_column], result, 'classification_score')\n",
    "                    #prune tree\n",
    "                    prune_node(prune_tree, n)\n",
    "                    #determine performance of pruned tree\n",
    "                    result = dt_classify(validation, prune_tree)\n",
    "                    eval2 = evaluation(validation[class_column], result, 'classification_score')\n",
    "                    #if performance of pruned tree is not worse, then keep the node pruned\n",
    "                    if eval2 >= eval1:\n",
    "                        tree = prune_tree\n",
    "                #count the new number of paths from the pruned tree\n",
    "                new_path_count, length = num_paths(tree)\n",
    "            #graph the pruned tree\n",
    "            graph_tree(data, tree, data.name + ' post', index)\n",
    "        #if no pruning then graph the tree\n",
    "        else:\n",
    "            graph_tree(data, tree, data.name, index)\n",
    "        #evaluate performance of the tree\n",
    "        result = dt_classify(test, tree)\n",
    "        eval_post.append(evaluation(test[class_column], result, 'classification_score'))\n",
    "        if len(eval_pre) != 0:\n",
    "            print(f'pre-pruning: {eval_pre[index]}')\n",
    "        print(f'post-pruning: {eval_post[index]}')\n",
    "    if len(eval_pre) != 0:\n",
    "        average_pre = sum(eval_pre)/len(eval_pre)\n",
    "        print(f'average pre-pruning: {average_pre}')\n",
    "    #determine the average of the performance metric over all folds\n",
    "    average = sum(eval_post)/len(eval_post)\n",
    "    print(f'average post-pruning: {average}')\n",
    "    return [average, eval_post, eval_pre]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Graph Tree\n",
    "`graph_tree` graphs the decision tree and displays the PDF of the graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def graph_tree(data, tree, name, index):\n",
    "    g = graphviz.Digraph(name=name + str(index), directory='graph output')\n",
    "    features = list(data)\n",
    "    tree_graphic(features, tree, None, None, g)\n",
    "    h = g.unflatten(stagger=2)\n",
    "    h.view()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tree Graphic\n",
    "`tree_graphic` uses graphviz to visualize the tree by connecting the nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def tree_graphic(features, tree, previous_node, previous_edge, g):\n",
    "    for key, value in tree.items():\n",
    "        p_edge = previous_edge\n",
    "        if type(value) is dict:\n",
    "            if key in features:\n",
    "                g.node(str(previous_node) + '->' + tree[key]['label'].name + str(previous_edge), label=tree[key]['label'].name, height = \"1\", width = \"1\")\n",
    "                p_node = str(previous_node) + '->' + tree[key]['label'].name + str(previous_edge)\n",
    "            else:\n",
    "                if list(tree[key])[0] == 'label':\n",
    "                    g.node(previous_node + '->' + str(tree[key]['label'].output) + str(key), label= str(tree[key]['label'].output))\n",
    "                    g.edge(previous_node, previous_node + '->' + str(tree[key]['label'].output) + str(key), label=str(key))\n",
    "                else:\n",
    "                    g.edge(previous_node, previous_node + '->' + tree[key][list(tree[key])[0]]['label'].name + str(key), label=str(key))\n",
    "                p_edge = str(key)\n",
    "                p_node = previous_node\n",
    "            tree_graphic(features, value, p_node, p_edge, g)\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Squared Error\n",
    "`squared_error` calculated the squared error of a sample of data relative to the mean of the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def squared_error(data):\n",
    "    error = 0\n",
    "    predicted_response = data.mean()\n",
    "    for sample in data:\n",
    "        error += (sample - predicted_response)**2\n",
    "    return error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Feature Regression\n",
    "`best_feature_regression` finds the best feature to use for the next node of a regression tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def best_feature_regression(data, class_column):\n",
    "    best = {}\n",
    "    #find the median of each feature\n",
    "    splits = data.median()\n",
    "    #determine the squared error of each feature split\n",
    "    for feature in data.keys():\n",
    "        if feature != class_column:\n",
    "            #create subset by splitting the data on the median of the feature\n",
    "            subset1 = data[class_column][data[feature] <= splits[feature]]\n",
    "            subset2 = data[class_column][data[feature] > splits[feature]]\n",
    "            #if a subset is empty then no split possible\n",
    "            if (len(subset1) == 0) or (len(subset2) == 0):\n",
    "                continue\n",
    "            #determine the MSE of the feature\n",
    "            error = sum([squared_error(subset1), squared_error(subset2)])/len(data)\n",
    "            best[feature] = error\n",
    "    #if no splits possible return None\n",
    "    if len(best) == 0:\n",
    "        return None, None, None\n",
    "    #find split that minimizes MSE\n",
    "    error = best[min(best, key=best.get)]\n",
    "    best = min(best, key=best.get)\n",
    "    return best, round(splits[best], 5), round(error, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Desision Tree Regression\n",
    "`decision_tree_regression` creates a decision tree for regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def decision_tree_regression(_data, class_column):\n",
    "    data = deepcopy(_data)\n",
    "    #named tuple structure to be used as label for each node\n",
    "    attr = namedtuple('attr', 'split name mse samples output')\n",
    "    #find the MSE of the current node\n",
    "    node_error = round(squared_error(data[class_column])/len(data), 5)\n",
    "    #find the feature to use for the next node\n",
    "    best_f, split, error = best_feature_regression(data, class_column)\n",
    "    #if MSE is 0 or no more splits possible create leaf\n",
    "    if node_error == 0 or best_f is None:\n",
    "        node = {'label': attr(split = None, name = None, mse = node_error, samples = len(data), output = round(data[class_column].mean(), 5))}\n",
    "        return node\n",
    "    #create new dictionary entry as new node for the tree\n",
    "    node = {best_f: {'True': {}, 'False': {}}}\n",
    "    #add label to the node\n",
    "    node[best_f]['label'] = attr(split = split, name = best_f + '<=' + str(split),\n",
    "                                          mse = error, samples = len(data), output = round(data[class_column].mean(), 5))\n",
    "    #create subsets for each branch of the new node\n",
    "    subset1 = data[data[best_f] <= split]\n",
    "    subset2 = data[data[best_f] > split]\n",
    "    #find the next node or leaf\n",
    "    if len(subset1) != 0:\n",
    "        node[best_f]['True'] = decision_tree_regression(subset1, class_column)\n",
    "    if len(subset2) != 0:\n",
    "        node[best_f]['False'] = decision_tree_regression(subset2, class_column)\n",
    "    return node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation Regression\n",
    "`cross_validation_regression` K fold cross validation for a regression decision tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def cross_validation_regression(data, class_column, post_prune = True):\n",
    "    eval_pre = []\n",
    "    eval_post = []\n",
    "    #creates the validation and test/train sets\n",
    "    folds, validation = k_fold_cross_validation_sets(data, 5, class_column, stratified=False)\n",
    "    #run each fold as the test set\n",
    "    for index, fold in enumerate(folds):\n",
    "        #create train test sets from folds\n",
    "        train, test = create_train_test(folds, index)\n",
    "        #create decision tree\n",
    "        tree = decision_tree_regression(train, class_column)\n",
    "        #if pruning is selected then prune the tree\n",
    "        if post_prune:\n",
    "            #graph the un-pruned tree\n",
    "            graph_tree(data, tree, data.name + ' pre', index)\n",
    "            #determine performance of the un-pruned tree\n",
    "            result = dt_classify(test, tree)\n",
    "            eval_pre.append(evaluation(test[class_column], result, 'mse'))\n",
    "            #determine number of paths in the tree\n",
    "            path_count, length = num_paths(tree)\n",
    "            new_path_count = 0\n",
    "            #keep pruning until the number of paths in the tree stops changing\n",
    "            while path_count > new_path_count:\n",
    "                #find nodes to be pruned\n",
    "                nodes = find_pruning_nodes(tree)\n",
    "                #determine number of paths in the tree\n",
    "                path_count, length = num_paths(tree)\n",
    "                #test performance of pruning each node individually against the validation set\n",
    "                for n in nodes:\n",
    "                    #copy the tree\n",
    "                    prune_tree = deepcopy(tree)\n",
    "                    #determine performance of the tree\n",
    "                    result = dt_classify(validation, prune_tree)\n",
    "                    eval1 = evaluation(validation[class_column], result, 'mse')\n",
    "                    #prune tree\n",
    "                    prune_node(prune_tree, n)\n",
    "                    #determine performance of pruned tree\n",
    "                    result = dt_classify(validation, prune_tree)\n",
    "                    eval2 = evaluation(validation[class_column], result, 'mse')\n",
    "                    #if performance of pruned tree is not worse, then keep the node pruned\n",
    "                    if eval2 >= eval1:\n",
    "                        tree = prune_tree\n",
    "                #count the new number of paths from the pruned tree\n",
    "                new_path_count, length = num_paths(tree)\n",
    "            #graph pruned tree\n",
    "            graph_tree(data, tree, data.name + ' post', index)\n",
    "        #if no pruning graph tree\n",
    "        else:\n",
    "            graph_tree(data, tree, data.name, index)\n",
    "        #evaluate performance of the tree\n",
    "        result = dt_classify(test, tree)\n",
    "        eval_post.append(evaluation(test[class_column], result, 'mse'))\n",
    "        if len(eval_pre) != 0:\n",
    "            print(f'pre-pruning: {eval_pre[index]}')\n",
    "        print(f'post-pruning: {eval_post[index]}')\n",
    "    if len(eval_pre) != 0:\n",
    "        average_pre = sum(eval_pre)/len(eval_pre)\n",
    "        print(f'average pre-pruning: {average_pre}')\n",
    "    #determine the average of the performance metric over all folds\n",
    "    average = sum(eval_post)/len(eval_post)\n",
    "    print(f'average post-pruning: {average}')\n",
    "    return [average, eval_post]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "cancer_data = load_breast_cancer('datasets/breast-cancer-wisconsin.data')\n",
    "cancer_data.name = 'Breast Cancer'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "cancer_data = cancer_data.astype(str)\n",
    "cancer_data.name = 'Breast Cancer Cat'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 0.9324324324324325\n",
      "post-pruning: 0.9459459459459459\n",
      "pre-pruning: 0.8918918918918919\n",
      "post-pruning: 0.918918918918919\n",
      "pre-pruning: 0.8243243243243243\n",
      "post-pruning: 0.8243243243243243\n",
      "pre-pruning: 0.8918918918918919\n",
      "post-pruning: 0.9459459459459459\n",
      "pre-pruning: 0.8767123287671232\n",
      "post-pruning: 0.863013698630137\n",
      "average pre-pruning: 0.8834505738615327\n",
      "average post-pruning: 0.8996297667530545\n",
      "CPU times: total: 2.69 s\n",
      "Wall time: 6.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cancer_cat_prune = cross_validation_classification(cancer_data, 'class', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "cancer_data = cancer_data.astype(float)\n",
    "cancer_data.name = 'Breast Cancer Num'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 0.9054054054054054\n",
      "post-pruning: 0.8918918918918919\n",
      "pre-pruning: 0.9054054054054054\n",
      "post-pruning: 0.9054054054054054\n",
      "pre-pruning: 0.9324324324324325\n",
      "post-pruning: 0.918918918918919\n",
      "pre-pruning: 0.9324324324324325\n",
      "post-pruning: 0.8648648648648649\n",
      "pre-pruning: 0.9452054794520548\n",
      "post-pruning: 0.9452054794520548\n",
      "average pre-pruning: 0.924176231025546\n",
      "average post-pruning: 0.9052573121066272\n",
      "CPU times: total: 2.23 s\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cancer_num_prune = cross_validation_classification(cancer_data, 'class', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "car_data = load_car('datasets/car.data')\n",
    "car_data.name = 'car'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 0.9028776978417267\n",
      "post-pruning: 0.8741007194244604\n",
      "pre-pruning: 0.9424460431654677\n",
      "post-pruning: 0.9028776978417267\n",
      "pre-pruning: 0.927536231884058\n",
      "post-pruning: 0.8985507246376812\n",
      "pre-pruning: 0.9309090909090909\n",
      "post-pruning: 0.8909090909090909\n",
      "pre-pruning: 0.9236363636363636\n",
      "post-pruning: 0.8945454545454545\n",
      "average pre-pruning: 0.9254810854873414\n",
      "average post-pruning: 0.8921967374716827\n",
      "CPU times: total: 19.1 s\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "car_class_prune = cross_validation_classification(car_data, 'class', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "house_votes_data = load_house_votes('datasets/house-votes-84.data')\n",
    "house_votes_data.name = 'house votes'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 0.9428571428571428\n",
      "post-pruning: 0.9571428571428572\n",
      "pre-pruning: 0.9714285714285714\n",
      "post-pruning: 0.9571428571428572\n",
      "pre-pruning: 0.8714285714285714\n",
      "post-pruning: 0.9428571428571428\n",
      "pre-pruning: 0.9714285714285714\n",
      "post-pruning: 0.9714285714285714\n",
      "pre-pruning: 0.9705882352941176\n",
      "post-pruning: 0.9705882352941176\n",
      "average pre-pruning: 0.945546218487395\n",
      "average post-pruning: 0.9598319327731092\n",
      "CPU times: total: 2.11 s\n",
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "house_class_prune = cross_validation_classification(house_votes_data, 'class', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "machine_data = load_machine('datasets/machine.data')\n",
    "machine_data.name = 'machine'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 3469.600143099416\n",
      "post-pruning: 30324.021428243876\n",
      "pre-pruning: 11111.269736842105\n",
      "post-pruning: 5736.723882531081\n",
      "pre-pruning: 4472.077486023392\n",
      "post-pruning: 20144.640507877037\n",
      "pre-pruning: 3126.292398128655\n",
      "post-pruning: 17428.324745911104\n",
      "pre-pruning: 3777.925675675676\n",
      "post-pruning: 27966.195248626496\n",
      "average pre-pruning: 5191.433087953849\n",
      "average post-pruning: 20319.981162637916\n",
      "CPU times: total: 5.73 s\n",
      "Wall time: 8.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "machine_reg_prune = cross_validation_regression(machine_data, 'PRP', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "forest_data = load_forest_fires('datasets/forestfires.data')\n",
    "forest_data.name = 'forest fires'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning: 753.4585705347523\n",
      "post-pruning: 761.2104960424476\n",
      "pre-pruning: 1728.4918212765956\n",
      "post-pruning: 462.20523497092125\n",
      "pre-pruning: 20317.112803693428\n",
      "post-pruning: 20459.360724596754\n",
      "pre-pruning: 38155.948650537626\n",
      "post-pruning: 6222.235928356534\n",
      "pre-pruning: 13998.573519957949\n",
      "post-pruning: 5156.573904964261\n",
      "average pre-pruning: 14990.71707320007\n",
      "average post-pruning: 6612.317257786184\n",
      "CPU times: total: 21.3 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest_reg_prune = cross_validation_regression(forest_data, 'area', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "abalone_data = load_abalone('datasets/abalone.data')\n",
    "abalone_data.name = 'abalone'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:1\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n",
      "Input \u001B[1;32mIn [40]\u001B[0m, in \u001B[0;36mcross_validation_regression\u001B[1;34m(data, class_column, post_prune)\u001B[0m\n\u001B[0;32m      9\u001B[0m train, test \u001B[38;5;241m=\u001B[39m create_train_test(folds, index)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m#create decision tree\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m tree \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m#if pruning is selected then prune the tree\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m post_prune:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m#graph the un-pruned tree\u001B[39;00m\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#find the next node or leaf\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset1) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset2, class_column)\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset1, class_column)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#find the next node or leaf\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset1) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset2, class_column)\n",
      "    \u001B[1;31m[... skipping similar frames: decision_tree_regression at line 23 (1 times)]\u001B[0m\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset1, class_column)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "    \u001B[1;31m[... skipping similar frames: decision_tree_regression at line 23 (2 times), decision_tree_regression at line 25 (1 times)]\u001B[0m\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset1, class_column)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "    \u001B[1;31m[... skipping similar frames: decision_tree_regression at line 23 (1 times)]\u001B[0m\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#find the next node or leaf\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset1) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 23\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdecision_tree_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset2) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     25\u001B[0m     node[best_f][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFalse\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m decision_tree_regression(subset2, class_column)\n",
      "Input \u001B[1;32mIn [39]\u001B[0m, in \u001B[0;36mdecision_tree_regression\u001B[1;34m(_data, class_column)\u001B[0m\n\u001B[0;32m      6\u001B[0m node_error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mround\u001B[39m(squared_error(data[class_column])\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(data), \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#find the feature to use for the next node\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m best_f, split, error \u001B[38;5;241m=\u001B[39m \u001B[43mbest_feature_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclass_column\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#if MSE is 0 or no more splits possible create leaf\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m node_error \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m best_f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Input \u001B[1;32mIn [38]\u001B[0m, in \u001B[0;36mbest_feature_regression\u001B[1;34m(data, class_column)\u001B[0m\n\u001B[0;32m     13\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;66;03m#determine the MSE of the feature\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m         error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([\u001B[43msquared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset1\u001B[49m\u001B[43m)\u001B[49m, squared_error(subset2)])\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(data)\n\u001B[0;32m     16\u001B[0m         best[feature] \u001B[38;5;241m=\u001B[39m error\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#if no splits possible return None\u001B[39;00m\n",
      "Input \u001B[1;32mIn [37]\u001B[0m, in \u001B[0;36msquared_error\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msquared_error\u001B[39m(data):\n\u001B[0;32m      2\u001B[0m     error \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 3\u001B[0m     predicted_response \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m data:\n\u001B[0;32m      5\u001B[0m         error \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (sample \u001B[38;5;241m-\u001B[39m predicted_response)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\generic.py:11124\u001B[0m, in \u001B[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001B[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  11106\u001B[0m \u001B[38;5;129m@doc\u001B[39m(\n\u001B[0;32m  11107\u001B[0m     _num_doc,\n\u001B[0;32m  11108\u001B[0m     desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturn the mean of the values over the requested axis.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  11122\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  11123\u001B[0m ):\n\u001B[1;32m> 11124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28mself\u001B[39m, axis, skipna, level, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\generic.py:10694\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  10686\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  10687\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  10688\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m lib\u001B[38;5;241m.\u001B[39mNoDefault \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mno_default,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  10692\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  10693\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 10694\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  10695\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanmean, axis, skipna, level, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  10696\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\generic.py:10646\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  10636\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m  10637\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m  10638\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  10641\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m  10642\u001B[0m     )\n\u001B[0;32m  10643\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_by_level(\n\u001B[0;32m  10644\u001B[0m         name, axis\u001B[38;5;241m=\u001B[39maxis, level\u001B[38;5;241m=\u001B[39mlevel, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  10645\u001B[0m     )\n\u001B[1;32m> 10646\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  10647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\n\u001B[0;32m  10648\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\series.py:4471\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   4467\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m   4468\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not implement \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4469\u001B[0m     )\n\u001B[0;32m   4470\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 4471\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\nanops.py:93\u001B[0m, in \u001B[0;36mdisallow.__call__.<locals>._f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(invalid\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 93\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;66;03m# we want to transform an object array\u001B[39;00m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;66;03m# ValueError message to the more typical TypeError\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;66;03m# e.g. this is normally a disallowed function on\u001B[39;00m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;66;03m# object arrays that contain strings\u001B[39;00m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(args[\u001B[38;5;241m0\u001B[39m]):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\nanops.py:146\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;66;03m# `mask` is not recognised by bottleneck, would raise\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;66;03m#  TypeError if called\u001B[39;00m\n\u001B[0;32m    145\u001B[0m     kwds\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 146\u001B[0m     result \u001B[38;5;241m=\u001B[39m bn_func(values, axis\u001B[38;5;241m=\u001B[39maxis, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;66;03m# prefer to treat inf/-inf as NA, but must compute the func\u001B[39;00m\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;66;03m# twice :(\u001B[39;00m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _has_infs(result):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "abalone_reg_prune = cross_validation_regression(abalone_data, 'rings', post_prune=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
